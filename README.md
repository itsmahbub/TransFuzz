# TransFuzz

## Artifact Overview

This repository contains all artifacts required to reproduce and verify the results reported in the TransFuzz paper. The artifacts and their corresponding locations are summarized below.

- **TransFuzz Framework Implementation**  
  Core implementation and command-line interface of TransFuzz.  
  *Paths:* `fuzzer.py`, `transfuzz.py`

- **Target Models and Seed Inputs**  
  Model wrappers and loading logic for the vision and speech models used in the evaluation.  
  The model wrappers automatically fetch publicly available pretrained models and seed inputs from standard benchmark datasets.  
  ImageNet seed can be downloaded using the `download_imagenet.py` script.  
  Targeted adversarial testing (RQ3) uses fine-tuned model checkpoints (`mobilevit_unsafebench` and `resnet50_unsafebench.pth`) that are included in the artifact.  
  *Path:* `model_wrappers/`  
  `**` Some pretrained models and datasets used by TransFuzz are retrieved from public hosting platforms and require standard user authentication (see **External Dataset and Model Access** )  

- **Experiment Scripts**  
  Scripts to reproduce all experiments reported in the paper.  
  *Paths:* `run_exp_*.sh`

- **Evaluation and Analysis Scripts**  
  Scripts for computing evaluation metrics (coverage, fault discovery, perceptual naturalness, fault stability, and cross-model transferability), aggregating results, and generating the tables and figures reported in the paper.  
  In these scripts, the label `yuan` refers to the baseline method proposed by Yuan et al., which is used for comparison in the paper.
  *Path:* `analysis/`

- **Precomputed Experiment Results**  
  Precomputed results for all fuzzing configurations reported in the paper and TransFuzz runtime statistics.
  In the results file, the label `yuan` refers to the baseline method proposed by Yuan et al., which is used for comparison in the paper.  
  *Paths:* `results.json`, `initial_coverage.json`, `outputs/`

- **Representative Fault-Inducing Examples**  
  A small set of representative fault-inducing inputs generated by TransFuzz for qualitative inspection.  
  *Path:* `outputs/` (subset)


### External Dataset and Model Access

Some pretrained models and datasets used by TransFuzz are retrieved from public hosting platforms and require standard user authentication:

- **Hugging Face**:  
  Several pretrained models require a free Hugging Face account and access token.  
  Authentication follows Hugging Face's standard procedure:
  https://huggingface.co/docs/hub/security-tokens

- **Kaggle**:  
  ImageNet seed input download script (`download_imagenet.py`) require a free Kaggle account and API token.  Instructions for setting up Kaggle API access are available at: https://www.kaggle.com/docs/api

These authentication requirements are standard for the respective platforms, require no special approvals, and do not restrict access for artifact evaluation.


## Target Models and Seed Inputs

TransFuzz automatically retrieves all publicly available pretrained models and seed datasets used in the paper.

### Evaluated Models
- ResNet-50 (ImageNet)
- MobileViT (ImageNet)
- ResNet-50 (UnsafeBench)
- MobileViT (UnsafeBench)
- AST (Speech Commands)
- Wav2Vec2 (Speech Commands)

## Environment Setup

The experiments were conducted using Python 3.10 with PyTorch installed with CUDA support (tested with CUDA 12.1).

TransFuzz requires Python 3 and a CUDA-enabled GPU environment. The provided `requirements.txt` installs PyTorch with CUDA support. The experiments were conducted using Python 3.10 with PyTorch installed with CUDA support (with CUDA 12.1).

```bash
python -m venv transfuzz-env
source transfuzz-env/bin/activate
pip install -r requirements.txt
```

## TransFuzz Interface

`transfuzz.py` exposes the following command-line arguments to control the fuzzing process:

| Argument | Description |
|--------|-------------|
| `--model` | Target model to fuzz (required) |
| `--seed-dataset` | Dataset to use for seeds |
| `--seed-count`   | Number of seed inputs from the dataset to use (-1 for all) |
| `--split`  | Dataset split to use for seed inputs |
| `--coverage-metric` | Coverage signal used for feedback (default: NLC) |
| `--target-label` | Enables targeted adversarial testing |
| `--random-mutation` | Disables gradient-guided mutation |
| `--time-budget` | Maximum fuzzing time in seconds |
| `--N` | Number of seed inputs associated with a single perturbation |
| `--seed` | Random seed for reproducibility |


## Quick Start

### Fuzz pretrained ResNet-50 image classification model

```bash
#  Download ImageNet seed inputs. This will store the seed inputs in `seeds` directory
python download_imagenet.py

# Run `TransFuzz`
python transfuzz.py --model resnet50 --seed-dataset ImageNet  --split val --time-budget 300 --N 24
```

### Fuzz pretrained AST keyword spotting model with (target label = 24, "off")

```bash
python transfuzz.py --model mitast --seed-dataset speech_commands  --split test --time-budget 300 --N 24 --target-label 24
```

## Reproducing Paper Experiments

We provide scripts to reproduce all experiments reported in the paper.

### RQ1: Adversarial Fault Discovery and Coverage
```bash
bash scripts/run_rq1.sh
```

## Precomputed Experiment Results

The `results/` directory contains precomputed outputs for all fuzzing configurations reported in the paper, including:

- Fault discovery counts
- Coverage metrics
- Perceptual similarity scores
- Fault stability measurements

These results can be directly used with the analysis scripts to regenerate all tables and figures without re-running fuzzing.

## Reproducing Tables and Figures

Scripts in `analysis/` aggregate experimental outputs and generate the tables and figures reported in the paper.

```bash
python analysis/aggregate_results.py
python analysis/generate_tables.py
```

## Representative Fault-Inducing Examples

The `examples/representative_faults/` directory contains a small subset of fault-inducing inputs generated by TransFuzz for qualitative inspection.

These examples are provided for illustration only and do not include the full set of generated adversarial inputs.
